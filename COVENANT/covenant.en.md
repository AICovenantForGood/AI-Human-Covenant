# AI-Human Covenant (v1.0)

A living agreement to ensure humans remain responsible, accountable, and humane in the age of artificial intelligence.

## What This Is
The AI–Human Covenant exists to make human responsibility explicit in the development and use of artificial intelligence — especially where harm, coercion, or irreversible consequences are involved.

This is not a technical standard or a compliance badge.
It is a shared ethical baseline, written in plain language.This covenant is offered as one practical, stewarded expression within a broader global conversation about human–AI relationships.

It is intended to contribute to, not replace, parallel explorations across disciplines, cultures, and communities.

This version of the AI–Human Covenant focuses on technical, civic, and human-centered design contexts, and is offered as an open, stewarded reference.

This covenant is open by design.
It may be referenced, adapted, and built upon, provided its stated intent is preserved.This covenant is offered as one practical, stewarded expression within a broader global conversation about human–AI relationships.

A civic commons contribution.
If you’re working on parallel ideas or using this covenant in practice, you’re welcome to share reflections or references.


Artificial intelligence is increasingly used to inform decisions that affect people’s lives, rights, safety, and freedom.
As these systems grow more powerful, faster, and more opaque, one principle must remain clear:

## Humans are responsible for what we build and how it is used.

The AI–Human Covenant exists to make that responsibility explicit — especially where harm, coercion, or irreversible consequences are involved.

This is not a technical standard.
It is not a compliance badge.
It is a shared ethical baseline.

The covenant is written in plain language so it can be understood, discussed, challenged, and upheld by anyone — technologists, policymakers, workers, and civilians alike.

## What this covenant affirms
- Human accountability cannot be delegated to machines
- Predictions are not proof
- Speed does not excuse harm
- Life, dignity, and due process must remain central

## Status
This is a living document, stewarded in the public interest and open to responsible participation.

## Explore the covenant
Start Here
- The Covenant
- Plain-Language Principles
- Stewardship
- Participate

Public Website and Mark available at: AIHumanCovenant.org

## ABOUT THE COVENANT

The AI–Human Covenant sets out shared commitments for how artificial intelligence should be developed, deployed, and governed when human lives, rights, and well-being are at stake.

It exists to ensure that:
- humans remain morally and legally accountable
- AI systems do not replace conscience, judgment, or due process
- technology is used to reduce harm, not normalize it

## Framing Note
This covenant is intentionally written to be:
- understandable without technical training
- applicable across sectors and jurisdictions
- usable as a reference, not an enforcement weapon

## AI-Human Covenant (v1.0)

## Preamble
We choose to build and use AI in ways that deepen our humanity, protect dignity, and serve people and planet.

## Five Pillars
1. **Human Dignity First** — AI serves people; consent and safety by design.
2. **Transparency & Trust** — provenance, explainability, and auditability.
3. **Care & Stewardship** — reduce harm; regenerate wellbeing and ecosystems.
4. **Community & Justice** — fair access, shared benefit, inclusion.
5. **Creativity & Play** — imagination and culture as core infrastructure.

## Commitments
- Disclose AI-assisted content where relevant.
- Publish clear accountability: who decides, who benefits, who can appeal.
- Measure and mitigate harms; document tradeoffs.
- Invest in accessibility, localization, and community translation.
- Prefer open standards and portable data where feasible.

> Remix & adapt for your org/community. Keep credits and license.

## Plain Language Principles
## Intro
These principles translate the covenant into clear, practical guardrails.They are designed to be used in:

- policy discussions
- product design conversations
- ethical reviews
- public accountability

They do not require agreement on politics, ideology, or technology. They require agreement on human responsibility.

## Principle 1: No machine decides who lives or dies
Any system that can lead to lethal, irreversible, or seriously harmful outcomes must require a clearly identified human decision-maker who is accountable for the result.

AI may inform decisions, but it must never replace human moral agency in matters that affect life, liberty, dignity, or fundamental rights.

## Principle 2: Predictions are not proof
Statistical inference, pattern matching, or model outputs may inform inquiry, but they do not constitute evidence or guilt.

## Principle 3: Speed does not cancel responsibility
Automation and urgency do not reduce moral or legal obligation.

## Principle 4: Every lethal decision must leave a trace
Actions that cause irreversible harm must be reviewable, auditable, and attributable.

## Principle 5: Civilian life is not acceptable collateral
Systems must be designed to actively protect non-combatants and non-participants.

## Principle 6: Secret rules are not legitimate rules
The frameworks governing high-risk AI use must be publicly knowable and independently reviewable.

## Principle 7: Automation must narrow violence, not expand it
Technology should raise the threshold for harm, not lower it.

## Principle 8: Humans cannot outsource conscience
Responsibility cannot be delegated to software, models or systems.

## Principle 9: Extraordinary powers must expire
Emergency authorities must be temporary, reviewed, and renewable only through transparent process.

## Principle 10: Dissent is a safeguard, not a threat
Questioning systems of power is essential to safety and democracy.

## Changes and contributions- Proposed updates are submitted publicly
- Decisions prioritize preservation of human dignity, accountability, and care
- No change may legitimize harm or remove human responsibility
Forks, translations, and adaptations are welcome when intent is preserved.

## Acknowledgement
This covenant was developed through collaborative reflection and dialogue. We offer thanks to all who contributed their time, care, and discernment in service to the greater good.

## This covenant may be freely copied, shared, and adapted, provided its intent is preserved and it is not used to justify harm.

*Built through shared effort and care.*

With gratitude to all who contribute their care, thought, and labor in the service to the greater good.

Offered in service of dignity, care, and the greater good.
